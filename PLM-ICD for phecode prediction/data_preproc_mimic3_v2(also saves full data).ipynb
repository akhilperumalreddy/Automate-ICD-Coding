{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICD Codes from Diagnosis and Procedures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(code, is_diag): ## leveraged from caml-mimic (for adding periods (dots) to ICD codes)\n",
    "    \"\"\"\n",
    "        Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "        Generally, procedure codes have dots after the first two digits, \n",
    "        while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = ''.join(code.split('.'))\n",
    "    if is_diag:\n",
    "        if code.startswith('E'):\n",
    "            if len(code) > 4:\n",
    "                code = code[:4] + '.' + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                code = code[:3] + '.' + code[3:]\n",
    "    else:\n",
    "        code = code[:2] + '.' + code[2:]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE FORM_ICD9_CODE\n",
      "0    1297         109   172335      1.0     40301         403.01\n",
      "1    1298         109   172335      2.0       486            486\n",
      "2    1299         109   172335      3.0     58281         582.81\n",
      "3    1300         109   172335      4.0      5855          585.5\n",
      "4    1301         109   172335      5.0      4254          425.4\n",
      " # unique ICD codes:  8994\n"
     ]
    }
   ],
   "source": [
    "## read data\n",
    "diag_df = pd.read_csv('../MIMIC_DATA/DIAGNOSES_ICD.csv')\n",
    "proc_df = pd.read_csv('../MIMIC_DATA/PROCEDURES_ICD.csv')\n",
    "\n",
    "## reformat codes\n",
    "diag_df['FORM_ICD9_CODE'] = diag_df['ICD9_CODE'].apply(lambda x: reformat(str(x), True))\n",
    "proc_df['FORM_ICD9_CODE'] = proc_df['ICD9_CODE'].apply(lambda x: reformat(str(x), False))\n",
    "\n",
    "## merge data\n",
    "all_df_codes = pd.concat([diag_df, proc_df])\n",
    "print(all_df_codes[:5])\n",
    "\n",
    "##save all codes to csv\n",
    "all_df_codes.to_csv('../MIMIC_DATA/all_codes.csv', index=False, columns=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'FORM_ICD9_CODE'],\n",
    "               header=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE'])\n",
    "\n",
    "\n",
    "all_df_codes = all_df_codes[['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'FORM_ICD9_CODE']]\n",
    "\n",
    "all_df_codes.rename(columns={'FORM_ICD9_CODE': 'ICD9_CODE'}, inplace=True)\n",
    "\n",
    "print(\" # unique ICD codes: \", len(all_df_codes['ICD9_CODE'].unique()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Discharge summaries (from Notes) and then Tokenize only non-numeric text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lower_nonnum(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    updated_text = [token.lower() for token in tokenizer.tokenize(text) if not token.isnumeric()]\n",
    "    updated_text = '\"'+ ' '.join(updated_text) + '\"'\n",
    "    return updated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/x/i/xianshi/miniconda3/envs/bert_hw/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "##code for processing discharge summaries, if we already did, not needed to run again\n",
    "\"\"\"\n",
    "notes_df = pd.read_csv('../MIMIC_DATA/NOTEEVENTS.csv') ## read Noteevents data\n",
    "\n",
    "notes_df = notes_df[notes_df['CATEGORY'] == 'Discharge summary'] ## filter for discharge summaries\n",
    "\n",
    "notes_df['TEXT'] = notes_df['TEXT'].apply(lambda x: tokenize_lower_nonnum(x)) ## tokenize, lower case, remove numbers\n",
    "\n",
    "notes_df = notes_df[['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'TEXT']] ## keep only relevant columns\n",
    "\n",
    "#write to csv\n",
    "notes_df.to_csv('../MIMIC_DATA/processed_discharge_summaries.csv', index=False)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # unique SUBJECT_IDs with discharge notes:  41127\n",
      " # unique HADM_IDs with discharge notes:  52726\n"
     ]
    }
   ],
   "source": [
    "##read processed discharge summaries\n",
    "dis_df = pd.read_csv('../MIMIC_DATA/processed_discharge_summaries.csv', dtype= {\"SUBJECT_ID\": int, 'HADM_ID': int}) ## read processed discharge summaries\n",
    "dis_df = dis_df.sort_values(['SUBJECT_ID', 'HADM_ID']) ## sort by subject id and hadm id\n",
    "\n",
    "## keep only relevant columns\n",
    "dis_df = dis_df[['SUBJECT_ID', 'HADM_ID', 'TEXT']]\n",
    "\n",
    "##key details\n",
    "print(\" # unique SUBJECT_IDs with discharge notes: \", len(dis_df['SUBJECT_ID'].unique()))\n",
    "print(\" # unique HADM_IDs with discharge notes: \", len(dis_df['HADM_ID'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48470</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID  HADM_ID                                               TEXT\n",
       "48470           3   145834  \"admission date discharge date date of birth s...\n",
       "4782            4   185777  \"admission date discharge date date of birth s...\n",
       "24476           6   107064  \"admission date discharge date date of birth s..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_df[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrate ICD codes from Diagnosis and Procedures with Discharge summaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # unique HADM_IDs in all_codes:  52726\n"
     ]
    }
   ],
   "source": [
    "all_df_codes.sort_values(['SUBJECT_ID', 'HADM_ID'], inplace=True) ## sort by subject id and hadm id\n",
    "\n",
    "##keep only the codes for which we have discharge summaries\n",
    "\n",
    "all_df_codes = all_df_codes[all_df_codes['HADM_ID'].isin(dis_df['HADM_ID'].unique())]\n",
    "\n",
    "all_df_codes.sort_values(['SUBJECT_ID', 'HADM_ID'], inplace=True)\n",
    "\n",
    "print (\" # unique HADM_IDs in all_codes: \", len(all_df_codes['HADM_ID'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "      <td>038.9;785.59;584.9;427.5;410.71;428.0;682.6;42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "      <td>042;136.3;799.4;276.3;790.7;571.5;041.11;V09.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>\"admission date discharge date date of birth s...</td>\n",
       "      <td>403.91;444.0;997.2;276.6;276.7;285.9;275.3;V15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID                                               TEXT  \\\n",
       "0           3   145834  \"admission date discharge date date of birth s...   \n",
       "1           4   185777  \"admission date discharge date date of birth s...   \n",
       "2           6   107064  \"admission date discharge date date of birth s...   \n",
       "\n",
       "                                           ICD9_CODE  \n",
       "0  038.9;785.59;584.9;427.5;410.71;428.0;682.6;42...  \n",
       "1  042;136.3;799.4;276.3;790.7;571.5;041.11;V09.0...  \n",
       "2  403.91;444.0;997.2;276.6;276.7;285.9;275.3;V15...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##grouping codes by HADM_ID and subject_id\n",
    "all_codes_df_2 = all_df_codes.groupby(['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].apply(list).reset_index()\n",
    "all_codes_df_2['ICD9_CODE'] = all_codes_df_2['ICD9_CODE'].apply(lambda x: ';'.join(x))\n",
    "#print(\"updated allcodes:\", all_codes_df_2[:5])\n",
    "\n",
    "##merge discharge summaries and codes\n",
    "notes_codes_df = pd.merge(dis_df, all_codes_df_2, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "notes_codes_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # unique HADM_IDs in merged data:  52726\n"
     ]
    }
   ],
   "source": [
    "print(\" # unique HADM_IDs in merged data: \", len(notes_codes_df['HADM_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59652"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes_codes_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Train, Validation and Test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc, dev_perc, test_perc = 0.8, 0.1, 0.1\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "shuffled_indices = torch.randperm(len(notes_codes_df)) ##\n",
    "\n",
    "train_df = notes_codes_df.iloc[shuffled_indices[:int(len(notes_codes_df)*train_perc)]]\n",
    "\n",
    "dev_df = notes_codes_df.iloc[shuffled_indices[int(len(notes_codes_df)*train_perc):int(len(notes_codes_df)*(train_perc+dev_perc))]]\n",
    "\n",
    "test_df = notes_codes_df.iloc[shuffled_indices[int(len(notes_codes_df)*(train_perc+dev_perc)):]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buidling Vocabulary using Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size based on train data:  50026\n"
     ]
    }
   ],
   "source": [
    "training_documents = train_df['TEXT'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=3)\n",
    "\n",
    "vectorizer.fit(training_documents)\n",
    "\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "print(\"Vocabulary size based on train data: \", len(vocab))\n",
    "\n",
    "##save vocab to file\n",
    "with open('../MIMIC_DATA/disnotes_vocab.txt', 'w') as f:\n",
    "    for word, index in vocab.items():\n",
    "        f.write(f'{word}\\t{index}\\n') ## writes word and index to a text file (with tab delimiter, reference code just saved the sorted list of words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort data based on length of the text for batching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/x/i/xianshi/miniconda3/envs/bert_hw/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/u/x/i/xianshi/miniconda3/envs/bert_hw/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/u/x/i/xianshi/miniconda3/envs/bert_hw/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_df[\"length\"] = train_df[\"TEXT\"].apply(lambda x: len(x.split()))\n",
    "train_df.sort_values(by=\"length\", inplace=True)\n",
    "\n",
    "dev_df[\"length\"] = dev_df[\"TEXT\"].apply(lambda x: len(x.split()))\n",
    "dev_df.sort_values(by=\"length\", inplace=True)\n",
    "\n",
    "test_df[\"length\"] = test_df[\"TEXT\"].apply(lambda x: len(x.split()))\n",
    "test_df.sort_values(by=\"length\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-train word embeddings (Excluded this step, as pretrained BERT doesn't need this)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Filter Top 50 ICD codes****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top codes: ['401.9', '38.93', '428.0', '427.31', '414.01', '96.04', '96.6', '584.9', '250.00', '96.71', '272.4', '518.81', '99.04', '39.61', '599.0', '96.72', '530.81', '272.0', '88.56', '285.9', '486', '38.91', '244.9', '36.15', '99.15', '285.1', '496', '276.2', '507.0', '88.72', '995.92', 'V58.61', '038.9', '37.22', '33.24', '311', '39.95', '585.9', '403.90', '305.1', '412', '410.71', '287.5', '276.1', '424.0', '45.13', 'V45.81', '37.23', '511.9', '93.90']\n"
     ]
    }
   ],
   "source": [
    "top_x = 50\n",
    "code_count = {}\n",
    "##count # times a code appeared in the full notes data\n",
    "for i in range(len(notes_codes_df)):\n",
    "    codes = notes_codes_df.iloc[i]['ICD9_CODE'].split(';')\n",
    "    for code in codes:\n",
    "        if code not in code_count:\n",
    "            code_count[code] = 1\n",
    "        else:\n",
    "            code_count[code] += 1\n",
    "\n",
    "##sort the codes based on their counts\n",
    "sorted_code_count = sorted(code_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "##get the top x codes\n",
    "top_x_codes = [code[0] for code in sorted_code_count[:top_x]]\n",
    "\n",
    "print(\"top codes:\", top_x_codes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save data before filtering for top 50 (XY added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove empty code rows\n",
    "train_df = train_df[train_df['ICD9_CODE'] != '']\n",
    "dev_df = dev_df[dev_df['ICD9_CODE'] != '']\n",
    "test_df = test_df[test_df['ICD9_CODE'] != '']\n",
    "\n",
    "train_df.rename(columns={\"TEXT\": \"sentence1\", \"ICD9_CODE\": \"label\"}, inplace=True)\n",
    "test_df.rename(columns={\"TEXT\": \"sentence1\", \"ICD9_CODE\": \"label\"}, inplace=True)\n",
    "dev_df.rename(columns={\"TEXT\": \"sentence1\", \"ICD9_CODE\": \"label\"}, inplace=True)\n",
    "\n",
    "##save train, dev, test data to csv\n",
    "train_df.to_csv('../PLM-ICD-master/data/mimic3/train_ds_notes_full.csv', index=False)\n",
    "dev_df.to_csv('../PLM-ICD-master/data/mimic3/dev_ds_notes_full.csv', index=False)\n",
    "test_df.to_csv('../PLM-ICD-master/data/mimic3/test_ds_notes_full.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save ALL_ICD_CODES.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds_notes = pd.concat([train_ds_notes, test_ds_notes, dev_ds_notes])\n",
    "all_ds_notes['label'] = all_ds_notes['label'].astype(str)\n",
    "\n",
    "ALL_ICD_CODES = all_ds_notes.label\n",
    "ALL_ICD_CODES = ALL_ICD_CODES[ALL_ICD_CODES != '']\n",
    "ALL_ICD_CODES = ALL_ICD_CODES.apply(lambda x: x.split(';')).explode().unique()\n",
    "len(ALL_ICD_CODES)\n",
    "pd.Series(ALL_ICD_CODES).to_csv('../PLM-ICD-master/data/mimic3/ALL_ICD_CODES.txt', sep='\\n', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_20164\\1185438997.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ICD9_CODE'] = df['ICD9_CODE'].apply(lambda x: filter_codes(x, top_x_codes))\n"
     ]
    }
   ],
   "source": [
    "##filter train, dev, test data based on top x codes\n",
    "def filter_codes(x, top_x_codes):\n",
    "    codes = x.split(';')\n",
    "    filtered_codes = [code for code in codes if code in top_x_codes]\n",
    "    return ';'.join(filtered_codes)\n",
    "\n",
    "dffss = [train_df, dev_df, test_df]\n",
    "\n",
    "for df in dffss:\n",
    "    df['ICD9_CODE'] = df['ICD9_CODE'].apply(lambda x: filter_codes(x, top_x_codes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove empty code rows\n",
    "train_df = train_df[train_df['ICD9_CODE'] != '']\n",
    "dev_df = dev_df[dev_df['ICD9_CODE'] != '']\n",
    "test_df = test_df[test_df['ICD9_CODE'] != '']\n",
    "\n",
    "\n",
    "##save train, dev, test data to csv\n",
    "train_df.to_csv('MIMIC_DATA/train_ds_notes.csv', index=False)\n",
    "dev_df.to_csv('MIMIC_DATA/dev_ds_notes.csv', index=False)\n",
    "test_df.to_csv('MIMIC_DATA/test_ds_notes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train data:  44998\n",
      "length of dev data:  5633\n",
      "length of test data:  5638\n"
     ]
    }
   ],
   "source": [
    "###length of train, dev, test data\n",
    "print(\"length of train data: \", len(train_df))\n",
    "print(\"length of dev data: \", len(dev_df))\n",
    "print(\"length of test data: \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save top x codes to file\n",
    "with open('MIMIC_DATA/top_x_codes.txt', 'w') as f:\n",
    "    for code in top_x_codes:\n",
    "        f.write(f'{code}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS769",
   "language": "python",
   "name": "cs769"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
