{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28425,"status":"ok","timestamp":1680101427050,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"VXl14JOQt7xW","outputId":"fa137b82-6e89-4fa6-8197-57d2e0eb5831"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sf54jtezt3L9"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import f1_score, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33373,"status":"ok","timestamp":1680101562023,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"QAVrWnzHu-XA","outputId":"49e7be4c-0998-4ce9-bf82-7daf18bb210d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtgHzHjpt3MD"},"outputs":[],"source":["###key hyperparameters\n","max_length_tokenization = 3072 ## max length of token IDs\n","padding_tokentization = True ## whether to pad the token IDs"]},{"cell_type":"markdown","metadata":{"id":"5KCXFQ72t3ME"},"source":["**0. Load Input data, split the text to sentences for BERT & Tokenize to IDs, onehot encoding of lables**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCW38YEQt3MG"},"outputs":[],"source":["##get all labels (top 50 as of now)\n","all_labels = pd.read_csv('/content/drive/MyDrive/CS769_SH/MI_DATA/top_x_codes.txt', header=None)\n","all_labels.columns = [\"ICD9_CODE\"]\n","all_labels = all_labels['ICD9_CODE'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlgEEURBt3MH"},"outputs":[],"source":["def split_text_to_sentences(text, tokenizer,max_length = 128, padding = False, token_length = 3072 ):\n","    text = text.replace('\"', '') ## to remove quotes at the beginning and end of the text\n","    #text = text.split(' ') ## to split the text into words\n","    encoded_dict = tokenizer(text, padding=padding, truncation=True, max_length=token_length, add_special_tokens=True)\n","    input_ids = encoded_dict['input_ids']\n","    sentences = []\n","    attention_masks = []\n","    token_type_ids = []\n","    for i in range(0, len(input_ids), max_length):\n","        sentences.append(input_ids[i:i+max_length]) ## last sentence may be less than max_length\n","        attention_masks.append(encoded_dict['attention_mask'][i:i+max_length])\n","        token_type_ids.append(encoded_dict['token_type_ids'][i:i+max_length])\n","        if len(sentences[-1]) < max_length: ## if last sentence is less than max_length, pad it with [PAD]\n","            # tl =len(sentences[-1][0]) ## length of token IDs generated by tokenizer\n","            # sentences[-1] = sentences[-1] + [[0]*tl]*(max_length - len(sentences[-1])) ## pad with 0\n","            # attention_masks[-1] = attention_masks[-1] + [[0]*tl]*(max_length - len(attention_masks[-1])) ## pad with 0\n","            # token_type_ids[-1] = token_type_ids[-1] + [[0]*tl]*(max_length - len(token_type_ids[-1])) ## pad with 0\n","\n","            sentences[-1] = sentences[-1] + [0]*(max_length - len(sentences[-1])) ## pad with 0\n","            attention_masks[-1] = attention_masks[-1] + [0]*(max_length - len(attention_masks[-1])) ## pad with 0\n","            token_type_ids[-1] = token_type_ids[-1] + [0]*(max_length - len(token_type_ids[-1])) ## pad with 0\n","\n","    return [sentences, attention_masks, token_type_ids]\n","\n","def labels_to_one_hot(labels, all_labels):\n","    one_hot_labels = []\n","    for label in labels:\n","        one_hot = [0]*len(all_labels)\n","        for code in label:\n","            one_hot[all_labels.index(code)] = 1\n","        one_hot_labels.append(one_hot)\n","    return one_hot_labels\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQf9zkvwt3MI"},"outputs":[],"source":["def data_pull(df, all_labels, padding_tokentization, max_length_tokenization ):\n","    tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\", use_fast=True)\n","    notes = df['TEXT'].apply(lambda x: split_text_to_sentences(x, tokenizer, 128,padding_tokentization, max_length_tokenization)) #list of list of sentences\n","    labels = df['ICD9_CODE'].apply(lambda x: x.split(';')) ##list of ICD9 codes\n","    notes = notes.values.tolist() ## convert to list\n","    labels = labels.values.tolist() ## convert to list\n","    one_hot_labels = labels_to_one_hot(labels, all_labels)\n","\n","    return notes, one_hot_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uYWeXTOt3MJ"},"outputs":[],"source":["train_df = pd.read_csv('/content/drive/MyDrive/CS769_SH/MI_DATA/train_ds_notes.csv')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680030506846,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"R4AQPLFg1PeF","outputId":"64fe6449-4466-4f52-a2c6-f1fd6d3f660b"},"outputs":[{"data":{"text/plain":["2291"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_df[:40000]['length'].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["0423eefc13a64d8d8cc119473f64426f","0c214fb7e1f244d3a51f7ceb2273e1fa","c65b62e819f545b8a8e63446b56fb95d","f6b2088613b04c039ded3b6c865ce317","109e2f32b23d43278aaa8eb1618dc0ac","5059927b15c64d7ab70fa8861851ae49","4769cff1ac464a35955fda46b3627296","d4b3028c218f452ebb55d709d3d476b3","fb6b6a933008499b83f3c844523fb57e","4a5aab00b29f472da8efbb6fb0692d82","36a56a938f214a068af93f6e9526f038","942a3eef9ce54ddc85c53f3bd8551293","b3211e5fb08048a0a606f643321d22e7","d2ce613876d34ca08001f355ff614e5d","5954b9066c94436489efc8ac2ded37ae","ef8f02c13cad41ccb0b0760d986f2f45","9db2857d9fb74344879335f53797ca6c","0677cc89233e4638a2a31c1cf3603d70","fd6b6967883f40b7ac656eb20f7a2efd","6de02d4602234ac2b438ae1154c4185b","d765d5293fc946b983e15773e3830c4f","4baf2208ceb745b4b3431d6175c5f958"]},"executionInfo":{"elapsed":271823,"status":"ok","timestamp":1680030778658,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"uOjdfV7Pt3MK","outputId":"3ea7035c-e2aa-4489-f0a0-772eb76e427f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0423eefc13a64d8d8cc119473f64426f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"942a3eef9ce54ddc85c53f3bd8551293","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_notes, train_labels = data_pull(train_df[:40000], all_labels,padding_tokentization, max_length_tokenization)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lwLNldN13qj"},"outputs":[],"source":["dev_df = pd.read_csv('/content/drive/MyDrive/CS769_SH/MI_DATA/dev_ds_notes.csv')\n","#TAKE one in 6 rows\n","dev_df = dev_df[:5000]\n","#dev_df = dev_df.iloc[::6, :]\n","dev_notes, dev_labels = data_pull(dev_df, all_labels,padding_tokentization, max_length_tokenization)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3X-5WE3r0PCK"},"outputs":[],"source":["##clearning memory\n","import gc\n","gc.collect()\n","del train_df\n","del dev_df"]},{"cell_type":"markdown","metadata":{"id":"CglmzhZ8t3ML"},"source":["**1. Main Model Definition (BERT + LabelAttention + Loss)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJNT57Pqt3MM"},"outputs":[],"source":["class ICD9_Detection(nn.Module):\n","    def __init__(self, num_labels):\n","        super(ICD9_Detection, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.dropout = nn.Dropout(0.1)\n","        self.linear_z = nn.Linear(768, 768)\n","        self.linear_a = nn.Linear(768, num_labels)\n","        self.linear_o = nn.Linear(768, num_labels)\n","        self.num_labels = num_labels\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        outputs = self.bert(input_ids.view(-1, 128), attention_mask=attention_mask.view(-1, 128), token_type_ids=token_type_ids.view(-1, 128))\n","        last_hidden_state = outputs[0].view(input_ids.shape[0],input_ids.shape[1]*input_ids.shape[2], 768) ##shape: (b, s*c, 768)\n","        z = torch.tanh(self.linear_z(last_hidden_state)) ##shape: (b, s*c, 768)\n","        a = torch.softmax(self.linear_a(z), dim=1).transpose(1,2) ##shape: (b, num_labels, s*c) weights for each label\n","        d = torch.matmul(a, last_hidden_state) ##shape: (b, num_labels, 768) weighted sum for each label (check matmul once again)\n","        logits = self.linear_o.weight.mul(d).sum(dim=2) ##shape: (num_labels) logits for each label\n","        return logits\n","    \n","    def loss(self, logits, labels):\n","        loss = nn.BCEWithLogitsLoss()\n","        return loss(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n","\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"2uSA1sFmt3MM"},"source":["**2. Train the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlge8OHqt3MN"},"outputs":[],"source":["def batch_convertor(training_data, training_labels, batch_size = 32):##add padding when # sentences differes across batches\n","    all_batches_sentences, all_batches_attention, all_batches_tokentype = [], [], []\n","    all_batches_labels = []\n","    for i in range(0, len(training_data), batch_size):\n","        batch = training_data[i:i+batch_size]\n","        max_num_sentences = max([len(x[0]) for x in batch])\n","        batch_sentences, batch_attention_masks, batch_token_type_ids = [], [], []\n","        for j in range(len(batch)):\n","            num_sentences = len(batch[j][0])\n","            batch_sentences.append(batch[j][0] + [[0]*128]*(max_num_sentences - num_sentences))\n","            batch_attention_masks.append(batch[j][1] + [[0]*128]*(max_num_sentences - num_sentences))\n","            batch_token_type_ids.append(batch[j][2] + [[0]*128]*(max_num_sentences - num_sentences))\n","\n","        all_batches_sentences.append(torch.tensor(batch_sentences))\n","        all_batches_attention.append(torch.tensor(batch_attention_masks))\n","        all_batches_tokentype.append(torch.tensor(batch_token_type_ids))\n","        all_batches_labels.append(torch.tensor(training_labels[i:i+batch_size]))\n","    \n","    return [all_batches_sentences, all_batches_attention,all_batches_tokentype], all_batches_labels\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TlOz1Jut3MN"},"outputs":[],"source":["## training by taking one example at a time\n","def train(model,training_notes, labels, num_epochs, optimizer, device, model_save_path = None, dev_notes = None, dev_labels = None, threshold=0.2):\n","    print('Training started')\n","    for epoch in range(num_epochs):\n","        epoch_loss = []\n","        model_save_path_curr = model_save_path\n","        #model.train()\n","        for i in range(len(training_notes[0])):\n","            note = training_notes[0][i].to(device) ##batched sentences of shape(batch_size, max_num_sentences, max_length=128)\n","            attention_mask = training_notes[1][i].to(device)\n","            token_type_ids = training_notes[2][i].to(device)\n","            label = labels[i].to(device)\n","            logits = model(note, attention_mask, token_type_ids)\n","            #print(logits, label)\n","            loss = model.loss(logits, label.float())\n","            #accuracy = model.accuracy(logits, label)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            torch.cuda.empty_cache()\n","            del note, attention_mask, token_type_ids, logits\n","            if i%2500 == 0:\n","                dev_micro_f1, dev_macro_f1 = evaluate_model(model, dev_notes, dev_labels, device)\n","                print('Epoch: {}, #Batches: {}, Loss: {}, Dev Micro F1: {}, Dev Macro F1: {}'.format(epoch, i, loss.item(), dev_micro_f1, dev_macro_f1))\n","\n","            epoch_loss.append(loss.item())\n","            del loss\n","        print('Epoch: {}, Loss: {}'.format(epoch, np.mean(epoch_loss)))\n","        ###save model\n","        model_save_path_curr = model_save_path_curr + str(epoch) + '.pt'\n","        torch.save(model.state_dict(), model_save_path_curr)\n","        print('Model saved to {}'.format(model_save_path_curr))\n","\n","    return model\n","\n","def evaluate_model (model, dev_notes, dev_labels, device=torch.device(\"cpu\"), threshold=0.2):\n","    #model.eval()\n","    with torch.no_grad():\n","        predictions = []\n","        for i in range(len(dev_notes[0])):\n","            note = dev_notes[0][i].to(device)\n","            attention_mask = dev_notes[1][i].to(device)\n","            token_type_ids = dev_notes[2][i].to(device)\n","            #label = torch.tensor(dev_labels[i]).to(device)\n","            logits = model(note, attention_mask, token_type_ids)\n","            #loss = model.loss(logits, label.float())\n","            for ll in range(len(logits)):#for each example in the batch\n","                logits_i = torch.sigmoid(logits[ll])\n","                logits_i = [1 if x>threshold else 0 for x in logits_i]\n","                #logits_i = logits_i.cpu().detach()\n","                predictions.append(logits_i) ## appending for each example in the batch/dataset\n","    \n","    ##f1_score calc\n","    del logits, note, attention_mask,token_type_ids\n","    micro_f1 = f1_score(torch.tensor(dev_labels).numpy(), torch.tensor(predictions).numpy(), average='micro')\n","    macro_f1 = f1_score(torch.tensor(dev_labels).numpy(), torch.tensor(predictions).numpy(), average='macro')\n","\n","    #print('Micro F1: {}, Macro F1: {}'.format(micro_f1, macro_f1))\n","\n","    return micro_f1, macro_f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3012,"status":"ok","timestamp":1680105232067,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"NbhhlhDvt3MO","outputId":"043806df-72df-484e-9bb6-782bf0c2b532"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU device is available\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["##train the model\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('GPU device is available')\n","else:\n","    device = torch.device(\"cpu\")\n","    print('GPU device is not available, using CPU instead')\n","    \n","model = ICD9_Detection(len(all_labels)).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-6)\n","model_save_path = '/content/drive/MyDrive/CS769_SH/saved_models/run_4_sh_icd_pl_weights_'\n","\n","##load pre-trained weights\n","model.load_state_dict(torch.load('/content/drive/MyDrive/CS769_SH/saved_models/run_3_sh_icd_pl_weights_0.pt'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1XlOA7Nt3MQ"},"outputs":[],"source":["##batch data generation for training\n","training_notes_batches, training_labels_batches = batch_convertor(train_notes, train_labels, batch_size = 4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fH0BnOX-2ARj"},"outputs":[],"source":["dev_notes_batches, dev_labels_batches = batch_convertor(dev_notes, dev_labels, batch_size = 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1680031731374,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"R6vrP9nQt3MR","outputId":"1a78be22-b51d-4e37-8c21-b8ce47bf945e"},"outputs":[{"data":{"text/plain":["(10000, 10000, 105, 105)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(training_notes_batches[0]), len(training_labels_batches), len(dev_notes_batches[0]), len(dev_labels_batches)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUCKkX3Ot3MR"},"outputs":[],"source":["model = train(model, training_notes_batches, training_labels_batches, num_epochs =10, optimizer= optimizer, device = device , model_save_path=model_save_path, dev_notes = dev_notes_batches, dev_labels = dev_labels, threshold=0.25)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1680105268160,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"jxQDnFOUt3MS","outputId":"575dc2ee-5ee2-4503-9450-c5ac3708ae66"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(625, 625)"]},"metadata":{},"execution_count":24}],"source":["len(dev_notes_batches[0]), len(dev_labels_batches)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2020884,"status":"ok","timestamp":1680107313494,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"N16G44GUl-bK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8848c2c7-402c-4ac6-e811-37e470bc3fc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["for threshold  0.25 micro_f1:  0.6337883122190437 macro_f1:  0.591586620381232\n","for threshold  0.3 micro_f1:  0.638507209499576 macro_f1:  0.5930755076319021\n","for threshold  0.35 micro_f1:  0.6422230393444346 macro_f1:  0.5939907651118143\n","for threshold  0.4 micro_f1:  0.6428069416662161 macro_f1:  0.5916769231424361\n"]}],"source":["for i in [0.25, 0.3, 0.35, 0.4]:\n","  micro_f1, macro_f1 = evaluate_model(model, dev_notes_batches, dev_labels, device, threshold=i)\n","  print(\"for threshold \", i, \"micro_f1: \", micro_f1, \"macro_f1: \", macro_f1)"]},{"cell_type":"markdown","metadata":{"id":"gU-4K8JNkEVD"},"source":["Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCxUGnADkGne"},"outputs":[],"source":["test_df = pd.read_csv('/content/drive/MyDrive/CS769_SH/MI_DATA/test_ds_notes.csv')\n","#TAKE one in 6 rows\n","test_df = test_df[:5013]\n","#test_df = test_df.iloc[::6, :]\n","test_notes, test_labels = data_pull(test_df, all_labels,padding_tokentization, max_length_tokenization)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agqapyn2k49C"},"outputs":[],"source":["test_notes_batches, test_labels_batches = batch_convertor(test_notes, test_labels, batch_size = 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680110239839,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"MtCaLEyblHfa","outputId":"e6850426-6f0a-4829-995b-d55d59136055"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["627"]},"metadata":{},"execution_count":31}],"source":["len(test_notes_batches[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":507993,"status":"ok","timestamp":1680110777469,"user":{"displayName":"sriharsha devarapu","userId":"16090814553419886240"},"user_tz":300},"id":"wFsghqRMlR-f","outputId":"369443a2-4df9-40a9-a9fd-a317e4da720a"},"outputs":[{"output_type":"stream","name":"stdout","text":["for threshold  0.35 macro_f1:  0.5952312652015899 micro_f1:  0.645972658896281\n"]}],"source":["micro_f1, macro_f1 = evaluate_model(model, test_notes_batches, test_labels, device, threshold=0.35)\n","print(\"for threshold \", 0.35, \"macro_f1: \", macro_f1, \"micro_f1: \", micro_f1)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"3bmi771","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0423eefc13a64d8d8cc119473f64426f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c214fb7e1f244d3a51f7ceb2273e1fa","IPY_MODEL_c65b62e819f545b8a8e63446b56fb95d","IPY_MODEL_f6b2088613b04c039ded3b6c865ce317"],"layout":"IPY_MODEL_109e2f32b23d43278aaa8eb1618dc0ac"}},"0677cc89233e4638a2a31c1cf3603d70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c214fb7e1f244d3a51f7ceb2273e1fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5059927b15c64d7ab70fa8861851ae49","placeholder":"​","style":"IPY_MODEL_4769cff1ac464a35955fda46b3627296","value":"Downloading (…)lve/main/config.json: 100%"}},"109e2f32b23d43278aaa8eb1618dc0ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36a56a938f214a068af93f6e9526f038":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4769cff1ac464a35955fda46b3627296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a5aab00b29f472da8efbb6fb0692d82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4baf2208ceb745b4b3431d6175c5f958":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5059927b15c64d7ab70fa8861851ae49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5954b9066c94436489efc8ac2ded37ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d765d5293fc946b983e15773e3830c4f","placeholder":"​","style":"IPY_MODEL_4baf2208ceb745b4b3431d6175c5f958","value":" 213k/213k [00:00&lt;00:00, 321kB/s]"}},"6de02d4602234ac2b438ae1154c4185b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"942a3eef9ce54ddc85c53f3bd8551293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3211e5fb08048a0a606f643321d22e7","IPY_MODEL_d2ce613876d34ca08001f355ff614e5d","IPY_MODEL_5954b9066c94436489efc8ac2ded37ae"],"layout":"IPY_MODEL_ef8f02c13cad41ccb0b0760d986f2f45"}},"9db2857d9fb74344879335f53797ca6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3211e5fb08048a0a606f643321d22e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9db2857d9fb74344879335f53797ca6c","placeholder":"​","style":"IPY_MODEL_0677cc89233e4638a2a31c1cf3603d70","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"c65b62e819f545b8a8e63446b56fb95d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4b3028c218f452ebb55d709d3d476b3","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb6b6a933008499b83f3c844523fb57e","value":385}},"d2ce613876d34ca08001f355ff614e5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6b6967883f40b7ac656eb20f7a2efd","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6de02d4602234ac2b438ae1154c4185b","value":213450}},"d4b3028c218f452ebb55d709d3d476b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d765d5293fc946b983e15773e3830c4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef8f02c13cad41ccb0b0760d986f2f45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6b2088613b04c039ded3b6c865ce317":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5aab00b29f472da8efbb6fb0692d82","placeholder":"​","style":"IPY_MODEL_36a56a938f214a068af93f6e9526f038","value":" 385/385 [00:00&lt;00:00, 12.4kB/s]"}},"fb6b6a933008499b83f3c844523fb57e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd6b6967883f40b7ac656eb20f7a2efd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}